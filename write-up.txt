There are four steps for doing this project: data exploration, feature engineering and data cleaning, building baseline and ML models, and model evaluation.
The structure of this page includes four parts based on the four questions.

## answer for Q1 (Data exploration)
#### data loading
1. The raw data has 29 attributes and 786363 records.
2. 'acqCountry','merchantCountryCode','posEntryMode','posConditionCode','transactionType' have null values.
3. 'echoBuffer','merchantCity','merchantState','merchantZip','posOnPremises','recurringAuthInd' are all null values. These attributes were dropped off. 
4. 'accountNumber','customerId' have the exactly same information. 'accountNumber' was dropped off.
5. 'transactionDateTime','accountOpenDate','dateOfLastAddressChange' were converted to data_time format.
6. 'cardPresent','expirationDateKeyInMatch','isFraud' are bool and were converted to numerical bool.
7. added 'CVVInMatch' attribute based on 'cardCVV' and 'enteredCVV'.

#### data description
1. The data has 5000 accounts. One account has 32850 transactions as the most but 783 fraud transactions as the most. Some accounts have significantly more fraudulent transactions than others.
2. The credit limit is from 250 to 50000.
3. The available money is from -1005.63 to 50000.
4. The transaction date is between 2016-1-1 to 2016-12-30.
5. The transaction amount is between 0 to 2011.54.
6. The current balance is from 0 to 47498.81.
7. AMC, EZ Putt Putt, Uber, Lyft, oldnavy.com are the most popular place for using this card. 
8. The acquisition countries merchant countries include US, MEX, CAN, and PR.
9. online_retail, fastfood, entertainment, food, online_gifts are the most popular categories.
10. transaction type includes PURCHASE, REVERSAL, ADDRESS_VERIFICATION, and others.
11. 44.87% of the transactions are card-presented transactions.
12. 0.13% of the transactions are expiration date mismatch transactions.
13. 0.89% of the transactions are CVV mismatch transactions.                
14. There is an imbalanced pattern for the fraud transaction, fraud transaction takes only 1.579%. 

## answer for Q2 (Data exploration with some plots)
1. The mean of transaction amounts is 136.98, the first quartile is 33.65, the median is 87.90, and the third quartile is 191.48. 
2. 3.4% of the transactions have an amount of less than 1 dollar, which is related to account validation.
3. 72.3% of transactions have money between 10 to 250 dollars.
4. 0.12% of transactions have money of more than 1000 dollars.
5. The top 5 categories of the mean transaction amount are personal care, subscriptions, rideshare, online_gifts, entertainment.
6. The top 5 categories of the max transaction amount are online_retail, fastfood, food, health, auto.
7. more transactions were made from 9pm to 9am (night) than from daytime.
8. more transactions were made during the weekend than on a weekday.
9. more transactions were made from July to Dec than Jan to June.

## answer for Q3 (duplicated transactions)
1. The method to calculate the amount of reversal transactions and the number of reversal transactions: <br>
a. The assumption is a reversal transaction should pair with a purchase or an address validation with the same customer Id, Last 4Digits of a card, transaction amount, and merchant name. I didn't add CVV and expiration date here as the identity since a client may get a new card after the existing is expired. <br>
b. Some transaction records have no transaction type. These could be reversal transactions paired with the existing purchase, address validation or purchase or address validation paired with reversal transactions, and reversal transactions paired with the unmarked purchase or address validation. <br>
2. The result of reversal transactions: <br>
total number of reversals:  18370 <br>
total amount of reversals:  2670554.23 <br>
3. The method to calculate the amount of reversal transactions and the number of multi-swipe transactions: <br>
a. The assumption is that multi-swipe transactions should have the same customer Id, Last 4Digits of a card, currentExpDate, cardCVV, transaction amount, and merchant name. These should be finished in a short time such as 180s (3 minutes). <br>
b. The transactions were sorted by time, grouped by customer Id, Last 4Digits of a card, currentExpDate, cardCVV, transaction amount, and merchant name, and calculated the time difference. The time difference is smaller than the 180s (3 minutes) were recognized as multi-swipe transactions. Only the first one was kept. <br> 
4. The result of multi-swipe transactions: <br>
total number of reversals:  13402 <br>
total amount of reversals:  1933949.11 <br>


## answer for Q4 (feature engineering, predictive model and model evaluation)
1. feature engineering <br>
a. night, weekend, month, amount, duration_acc, duration_add, money, fraudRatio, mcc_ratio, mnc_ratio were created. <br>
b. The distribution of a feature in fraudulent transactions and non-fraud transactions showed up. <br>
c. Using the stepwise method, the irrelative feature was dropped off. <br>
2. predictive model <br>
a. 75% training and 25% testing  <br>
b. since this is imbalanced data, there are two ways to deal with it. <br>
I tried random oversampling, random undersampling, and SMOTE of training data. <br>
I also tried to use the original data but with a class-weighted loss function (more penalty if a minority was misclassified). <br>
c. I tried three baseline models: decision tree, logistic regression, and random forest <br>
d. I tried a grid search to find the best parameter combination of random forest <br>
3. model evaluation <br>
a. Metrics: roc score, roc curve, precision, false alarm rate, and accuracy score <br>
precision and false alarm rate are important since a false alarm can lead to a bad customer experience but a missing can be detected by other models. <br>
4. Results <br>
a. The random undersampling dataset provides the best models in all three models. <br>
b. A class-weighted loss function for models with the original data didnâ€™t perform as well as the model with the balanced input. <br> 
c. Random forest (n_estimators = 300, max_depth=9, max_leaf_nodes=18) has the best performance in all three models with  <br>
    auc:0.778 <br>
    AccuracyScore:0.734 <br>
    Precision:0.996 <br>
    False Alarm Rate:0.176 <br>
d. all three models can output the probability of a transaction being a fraud, which can be used by other models with an expert-defined threshold to define if it is a fraud or not.  <br>

## discussion
1. The ideas I tried but not working well
a. For the predictive model, some anomaly detection methods were tried in this study, such as Local Outlier Factor and Isolation Forest
b. For the predictive model, KNN was tried in this study
c. For feature engineering, TomekLinks method was tried for undersampling the majority class, but it is too slow. 
c. For feature engineering, PCA was used to select the most correlated features

2. The ideas I would suggest trying in the future
a. For the predictive model, an artificial neural network should be tested as a supervised classification method
b. For the predictive model, k means should be tested as a clustering method to see if the account can be segmented into the group with a high probability of fraud and a low probability of fraud. 
c. For model evaluation, a precision-recall curve could be used 